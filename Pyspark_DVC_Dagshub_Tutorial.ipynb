{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pyspark-DVC-Dagshub Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6q9DjAXiCdWg",
        "180YYgPYRRG-",
        "psF3CtU0Rnnc",
        "TBX18_KOCNUN",
        "5qKKmr0iPxW8",
        "0xGeSTgqPzYM",
        "Cvi0LO-EOsxi",
        "mqSIiWsRKdi7",
        "mkUSZHpprPod",
        "BIPbycQ9KkTb",
        "zm96Vxt55C4f",
        "PqwcpKyD6a4w",
        "Clf4AiGQL-b5",
        "idV9fU3cKgG8"
      ],
      "toc_visible": true,
      "mount_file_id": "1ef3CkMTzKcP-mg0CAF9dKfo5B3np6yj6",
      "authorship_tag": "ABX9TyM5JfW88nt60eP0t5JxzZe0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prayas99/Pyspark-DVC-Dagshub-Tutorial/blob/main/Pyspark_DVC_Dagshub_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q9DjAXiCdWg"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkxGkK-P-TB3"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-CZhSjT18Tp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941acd0b-0ca8-4d4c-abd3-f805325a6b13"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 64kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 18.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=2737613b823a3c6740c864bdfa4f04bafd2a89cc84a72401d2bdbabc3adc94ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CO0fOP9CWwm",
        "outputId": "eb218c67-8025-43f5-8b2a-6c1af8126655"
      },
      "source": [
        "!pip install sk-dist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sk-dist\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/a2/69d38208de981c980eb8513348a82076b26ee52f2066b898d73252b74b95/sk-dist-0.1.9.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 20kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 6.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from sk-dist) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from sk-dist) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sk-dist) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sk-dist) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sk-dist) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->sk-dist) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->sk-dist) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->sk-dist) (1.15.0)\n",
            "Building wheels for collected packages: sk-dist\n",
            "  Building wheel for sk-dist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sk-dist: filename=sk_dist-0.1.9-cp37-none-any.whl size=51838 sha256=cd8f13409ce4a597360947a6f180d1586022227ce3f540f58fc358fca7079a1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/fa/b7/e4c8f3f076a7c907655ea401351658200528b2e73981afb6ea\n",
            "Successfully built sk-dist\n",
            "Installing collected packages: sk-dist\n",
            "Successfully installed sk-dist-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXtg5pwtCKzP"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold  # import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "import json\n",
        "import random\n",
        "import pymongo\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "# from joblibspark import register_spark\n",
        "from joblib import parallel_backend, Parallel, delayed\n",
        "from pprint import pprint\n",
        "import pyspark\n",
        "from itertools import islice\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pickle\n",
        "import time\n",
        "from skdist.distribute.search import DistGridSearchCV\n",
        "from sklearn.datasets import load_breast_cancer, load_boston\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from pyspark.sql import SparkSession\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj-wP9AiKI_N"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, balanced_accuracy_score, average_precision_score, \\\n",
        "    mean_squared_error, r2_score, brier_score_loss\n",
        "from sklearn.utils import resample\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "import random\n",
        "import string\n",
        "import datetime\n",
        "import numpy as np\n",
        "import importlib\n",
        "import sys  \n",
        "import sklearn.cluster as cluster\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "from scipy.stats import skew\n",
        "import lightgbm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split, learning_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from xgboost import plot_importance, to_graphviz\n",
        "from sklearn.metrics import make_scorer, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import brier_score_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.INFO)\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad as torch_grad\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "rcParams['figure.figsize'] = 9,5\n",
        "randomState = 5\n",
        "np.random.seed(randomState)\n",
        "import pickle\n",
        "from typing import Tuple\n",
        "\n",
        "import logging"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UNraxUxKceE"
      },
      "source": [
        "def build_metrics_df(df1, method, testY, testY_pred, testY_prob):\n",
        "    df = pd.DataFrame(columns = ['Method','Precision','Recall','Bal_Acc','AUPRC', 'AUC-ROC', 'GINI','#1', 'Brier'])\n",
        "    df = df.append({'Method' : str(method),\n",
        "                     'Precision' : precision_score(testY, testY_pred), \n",
        "                    'Recall' : recall_score(testY, testY_pred), \n",
        "                   'Bal_Acc' : balanced_accuracy_score(testY, testY_pred),\n",
        "                    'AUPRC' : average_precision_score(testY,testY_prob), \n",
        "                     'AUC-ROC' : roc_auc_score(testY, testY_prob), \n",
        "                   'GINI' : 2*(roc_auc_score(testY, testY_prob))-1, \n",
        "                    '#1' : testY_pred.sum(),\n",
        "                     'Brier' : (1/brier_score_loss(testY, testY_prob)/10000)}, \n",
        "                ignore_index = True)\n",
        "    frames = [df1, df]\n",
        "    df_merged = pd.concat(frames)\n",
        "    return df_merged\n",
        "df_metrics_empty = pd.DataFrame(columns = ['Method','Precision','Recall','Bal_Acc','AUPRC', 'AUC-ROC', 'GINI','#1' ,'Brier'])\n",
        "\n",
        "def get_cat_dims(X, cat_cols) -> list:\n",
        "    \"\"\"\n",
        "    Takes a pd.DataFrame and a list of columns and returns a list of levels/cardinality per column in the same order.\n",
        "    \"\"\"\n",
        "    return [(X[col].nunique()) for col in cat_cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enter dataset path"
      ],
      "metadata": {
        "id": "180YYgPYRRG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_dataset = 'put_path_to_dataset'"
      ],
      "metadata": {
        "id": "XjqkoLADRUTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building train-test data"
      ],
      "metadata": {
        "id": "psF3CtU0Rnnc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Z0TXWTNSsM"
      },
      "source": [
        "df_orig = pd.read_csv(path_to_dataset + \"/hmeq.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Raw3MVEk4sO",
        "outputId": "2ca80e83-5a1d-4100-dcc5-c4ea5f851132"
      },
      "source": [
        "X = df_orig.sample(frac=1, random_state=randomState)\n",
        "Y = X['BAD']\n",
        "del X['BAD']\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5960, 12)\n",
            "(5960,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2F5gflQSySV"
      },
      "source": [
        "cat_cols = ['REASON', 'JOB']\n",
        "num_cols = ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG',\n",
        "            'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']\n",
        "\n",
        "target_col = 'BAD'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlaUmmN_F5vJ",
        "outputId": "f7248f59-cf83-4d2e-cf76-78a661b0ebde"
      },
      "source": [
        "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.1, \\\n",
        "                                                random_state = 5)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "cat_dims = get_cat_dims(trainX, cat_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5364, 12)\n",
            "(596, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohZE9SwIJ0GP",
        "outputId": "5b4dbea1-dc8d-4b13-c8f8-372a6e124747"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "num_prep = make_pipeline(SimpleImputer(strategy='mean'),\n",
        "                         StandardScaler())\n",
        "cat_prep = make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
        "                         OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "prep = ColumnTransformer([\n",
        "    ('num', num_prep, num_cols),\n",
        "    ('cat', cat_prep, cat_cols)],\n",
        "    remainder='drop')\n",
        "trainX = prep.fit_transform(trainX)\n",
        "trainX = pd.DataFrame(trainX)\n",
        "testX = prep.transform(testX)\n",
        "testX = pd.DataFrame(testX)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5364, 18)\n",
            "(596, 18)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7z37pqXLbOA"
      },
      "source": [
        "X_res = pd.read_csv(path_to_dataset + \"/X_res_tosave01.csv',index_col=0\").values\n",
        "y_res = pd.read_csv(path_to_dataset + \"/y_res_tosave01.csv',index_col=0\").values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBX18_KOCNUN"
      },
      "source": [
        "# Hyperparameter Tuning using Sk-dist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb8bGkD_3pzw"
      },
      "source": [
        "def generate_random_configuration():\n",
        "    params = {'learning_rate': random.uniform(0.01, 0.25),\n",
        "              'colsample_bytree': random.uniform(0.8, 1.0),\n",
        "              'subsample': random.uniform(0.5, 1.0),\n",
        "              'n_estimators': int(math.floor(random.uniform(100, 3000))),\n",
        "              'reg_alpha': random.uniform(0.01, 0.5),\n",
        "              'max_depth': int(math.floor(random.uniform(3, 15))),\n",
        "              'gamma': int(math.floor(random.uniform(0, 10))),\n",
        "              'nthread':1\n",
        "              }\n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2WTuH3W6Eut",
        "outputId": "a5d6fae7-48db-4e5b-8ec9-02ff9229f38f"
      },
      "source": [
        "\n",
        "# spark session initialization\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "### XGBClassifier ###\n",
        "\n",
        "# sklearn variables\n",
        "cv = 5\n",
        "clf_scoring = \"roc_auc\"\n",
        "reg_scoring = \"neg_mean_squared_error\"\n",
        "\n",
        "# load sample data (binary target)\n",
        "data = load_breast_cancer()\n",
        "X = X_res\n",
        "y = y_res\n",
        "\n",
        "grid = dict(\n",
        "    learning_rate=[0.05, 0.01],\n",
        "    max_depth=[4, 6, 8],\n",
        "    colsample_bytree=[0.6, 0.8, 1.0],\n",
        "    n_estimators=[100, 200, 300],\n",
        ")\n",
        "start = time.time()\n",
        "### distributed grid search\n",
        "model = DistGridSearchCV(XGBClassifier(), grid, sc, cv=cv, scoring=clf_scoring)\n",
        "# distributed fitting with spark\n",
        "model.fit(X, y)\n",
        "# predictions on the driver\n",
        "preds = model.predict(X)\n",
        "probs = model.predict_proba(X)\n",
        "\n",
        "# results\n",
        "print(\"-- Grid Search --\")\n",
        "print(\"Train time: {0}\".format(time.time() - start))\n",
        "print(\"Best Score: {0}\".format(model.best_score_))\n",
        "print(\"Best colsample_bytree: {0}\".format(model.best_estimator_.colsample_bytree))\n",
        "print(\"Best learning_rate: {0}\".format(model.best_estimator_.learning_rate))\n",
        "print(\"Best max_depth: {0}\".format(model.best_estimator_.max_depth))\n",
        "print(\"Best n_estimators: {0}\".format(model.best_estimator_.n_estimators))\n",
        "print(pickle.loads(pickle.dumps(model)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Grid Search --\n",
            "Train time: 431.4376826286316\n",
            "Best Score: 0.9844365224873773\n",
            "Best colsample_bytree: 0.6\n",
            "Best learning_rate: 0.05\n",
            "Best max_depth: 8\n",
            "Best n_estimators: 200\n",
            "DistGridSearchCV(cv=5, error_score='raise-deprecating',\n",
            "                 estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
            "                                         colsample_bylevel=1,\n",
            "                                         colsample_bynode=1, colsample_bytree=1,\n",
            "                                         gamma=0, learning_rate=0.1,\n",
            "                                         max_delta_step=0, max_depth=3,\n",
            "                                         min_child_weight=1, missing=nan,\n",
            "                                         n_estimators=100, n_jobs=1,\n",
            "                                         nthread=None,\n",
            "                                         objective='binary:logistic',\n",
            "                                         random_state=0, reg_alpha=0,\n",
            "                                         reg_lambda=1, scale_pos_weight=1,\n",
            "                                         seed=None, silent=None, subsample=1,\n",
            "                                         verbosity=1),\n",
            "                 iid='warn', n_jobs=None,\n",
            "                 param_grid={'colsample_bytree': [0.6, 0.8, 1.0],\n",
            "                             'learning_rate': [0.05, 0.01],\n",
            "                             'max_depth': [4, 6, 8],\n",
            "                             'n_estimators': [100, 200, 300]},\n",
            "                 partitions='auto', pre_dispatch='2*n_jobs', preds=False,\n",
            "                 refit=True, return_train_score=False, sc=None,\n",
            "                 scoring='roc_auc', verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qKKmr0iPxW8"
      },
      "source": [
        "# Tuned Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0b9tHsbC3Wm"
      },
      "source": [
        "testY_pred = model.predict(testX.values)\n",
        "testY_prob = model.predict_proba(testX.values)[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "IUTiZ9sKMRkg",
        "outputId": "9df6cab3-df3c-4a4a-d7ce-cc2bfbdb6543"
      },
      "source": [
        "# df_metrics_SMOTE_XGB\n",
        "df_metrics_GAN_XGB =build_metrics_df(df_metrics_empty,\\\n",
        "      'GAN_XGB', testY,testY_pred, testY_prob).round(5)  \n",
        "df_metrics_GAN_XGB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Bal_Acc</th>\n",
              "      <th>AUPRC</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>GINI</th>\n",
              "      <th>#1</th>\n",
              "      <th>Brier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GAN_XGB</td>\n",
              "      <td>0.94792</td>\n",
              "      <td>0.79825</td>\n",
              "      <td>0.89394</td>\n",
              "      <td>0.94696</td>\n",
              "      <td>0.97827</td>\n",
              "      <td>0.95654</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.00264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Method  Precision   Recall  Bal_Acc  ...  AUC-ROC     GINI    #1    Brier\n",
              "0  GAN_XGB    0.94792  0.79825  0.89394  ...  0.97827  0.95654  96.0  0.00264\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xGeSTgqPzYM"
      },
      "source": [
        "# Original Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJzBGTsiMSmB"
      },
      "source": [
        "clf = XGBClassifier(max_depth = 3,   \\\n",
        "                n_jobs = 4)\n",
        "probabilities = clf.fit(X_res,y_res).predict_proba(testX.values)\n",
        "testY_prob = probabilities[:, 1]\n",
        "testY_pred = np.where(testY_prob > 0.5, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "5KcNKckQMTyB",
        "outputId": "cf3940b1-4cd0-430d-8d0b-5a2061b81821"
      },
      "source": [
        "# df_metrics_SMOTE_XGB\n",
        "df_metrics_GAN_XGB =build_metrics_df(df_metrics_empty,\\\n",
        "      'GAN_XGB', testY,testY_pred, testY_prob).round(5)  \n",
        "df_metrics_GAN_XGB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Bal_Acc</th>\n",
              "      <th>AUPRC</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>GINI</th>\n",
              "      <th>#1</th>\n",
              "      <th>Brier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GAN_XGB</td>\n",
              "      <td>0.87097</td>\n",
              "      <td>0.71053</td>\n",
              "      <td>0.84282</td>\n",
              "      <td>0.86467</td>\n",
              "      <td>0.94693</td>\n",
              "      <td>0.89386</td>\n",
              "      <td>93</td>\n",
              "      <td>0.00159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Method  Precision   Recall  Bal_Acc    AUPRC  AUC-ROC     GINI  #1    Brier\n",
              "0  GAN_XGB    0.87097  0.71053  0.84282  0.86467  0.94693  0.89386  93  0.00159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY1ijhknuAPb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvi0LO-EOsxi"
      },
      "source": [
        "# DVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqSIiWsRKdi7"
      },
      "source": [
        "# Configure DAGsHub & Git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdco6DJEr1Hs"
      },
      "source": [
        "import requests\n",
        "import getpass\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScoLtmkOSTLE"
      },
      "source": [
        "**Set Environment Variables**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v3Pnf5XqgJS",
        "cellView": "form"
      },
      "source": [
        "#@title Enter the repository name for the project:\n",
        "\n",
        "REPO_NAME= \"mark2\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx-CctUEqxlK",
        "cellView": "form"
      },
      "source": [
        "#@title Enter the username of your DAGsHub account:\n",
        "\n",
        "USER_NAME = \"prayas99\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc9DWFHFqxaF",
        "cellView": "form"
      },
      "source": [
        "#@title Enter the email for your DAGsHub account:\n",
        "\n",
        "EMAIL = \"prayas99@gmail.com\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyMcM1c7q9Ao"
      },
      "source": [
        "We take security very seriously and don't want your DAGsHub password to be saved in the notebook runtime. Thus, we created an API that generates an access token to your DAGsHub account. With this token, you will push your Git tracked files without saving the password as a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa6xePsDH6gs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d33a3f-6c90-411b-d1e0-a6b0986ea8f8"
      },
      "source": [
        "r = requests.post('https://dagshub.com/api/v1/user/tokens', \n",
        "                  json={\"name\": f\"colab-token-{datetime.datetime.now()}\"}, \n",
        "                  auth=(USER_NAME, getpass.getpass('DAGsHub password:')))\n",
        "r.raise_for_status()\n",
        "TOKEN=r.json()['sha1']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DAGsHub password:··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-KHaV-h9CnD"
      },
      "source": [
        "**Configure Git**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1CPZP15Npnj"
      },
      "source": [
        "!git config --global user.email {EMAIL}\n",
        "!git config --global user.name {USER_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPNKFBEFTlkH"
      },
      "source": [
        "**Clone the Repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZdQl7CgCf9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6703ee-bed0-4085-cbf3-2b1fb557e7db"
      },
      "source": [
        "!git clone https://dagshub.com/{USER_NAME}/{REPO_NAME}.git\n",
        "\n",
        "%cd {REPO_NAME}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mark2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0)\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "/content/mark2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkUSZHpprPod"
      },
      "source": [
        "# Install and Configure DVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEOF1GMt9pIa"
      },
      "source": [
        "**Initialize DVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKazlYv0rKoC",
        "outputId": "c1f37b67-906c-43d3-f3fd-46c55543b518"
      },
      "source": [
        "# Install DVC\n",
        "!pip install dvc &> /dev/null \n",
        "\n",
        "# Import DVC package - relevant only when working in a Colab environment\n",
        "import dvc\n",
        "\n",
        "# Initilize DVC in the local directory\n",
        "!dvc init &> /dev/null \n",
        "\n",
        "# Track the changes with git\n",
        "!git add .dvc .dvcignore .gitignore\n",
        "!git commit -m \"Initialize DVC\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master fddb58a] Initialize DVC\n",
            " 9 files changed, 515 insertions(+)\n",
            " create mode 100644 .dvc/.gitignore\n",
            " create mode 100644 .dvc/config\n",
            " create mode 100644 .dvc/plots/confusion.json\n",
            " create mode 100644 .dvc/plots/confusion_normalized.json\n",
            " create mode 100644 .dvc/plots/default.json\n",
            " create mode 100644 .dvc/plots/linear.json\n",
            " create mode 100644 .dvc/plots/scatter.json\n",
            " create mode 100644 .dvc/plots/smooth.json\n",
            " create mode 100644 .dvcignore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQcEaaF892KW"
      },
      "source": [
        "**Configure DVC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F2jzfIN2yCA"
      },
      "source": [
        "# Set DVC remote storage as 'DAGsHub storage'\n",
        "!dvc remote add origin --local https://dagshub.com/{USER_NAME}/{REPO_NAME}.dvc\n",
        "\n",
        "# General DVC configuration\n",
        "!dvc remote modify --local origin auth basic\n",
        "!dvc remote modify --local origin user {USER_NAME}\n",
        "!dvc remote modify --local origin password {TOKEN}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXQ9pRaRQsFj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIPbycQ9KkTb"
      },
      "source": [
        "# Project Setup \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWuJEuO5RHca"
      },
      "source": [
        "At this point, we want to add the required files for our ML project to the local directory. We will use the dvc get command that downloads files from a Git repository or DVC storage without tracking them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUMzCAbgT-Yr"
      },
      "source": [
        "**Download the project's files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv3k5NWh38FZ",
        "outputId": "0cd6f448-aff5-41e9-a072-334e22c263e3"
      },
      "source": [
        "!dvc get https://dagshub.com/nirbarazida/hello-world requirements.txt\n",
        "!dvc get https://dagshub.com/nirbarazida/hello-world src\n",
        "!dvc get https://dagshub.com/nirbarazida/hello-world-files data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\n",
            "!\n",
            "39e09c977c41d69815f5631a4f7fc3b0.dir          |0.00 [00:00,       ?it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tdcm_muUCCz"
      },
      "source": [
        "**Install Requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZXyUglvswaw"
      },
      "source": [
        "!pip install -r requirements.txt &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBD_hFmRRNAw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm96Vxt55C4f"
      },
      "source": [
        "# Track Files Using DVC and Git "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-5vFakF5O05"
      },
      "source": [
        "The data directory contains the data sets for this project, which are quite big. Thus, we will track this directory using DVC and use Git to track the rest of the project's files.\n",
        "\n",
        "**Track Files with DVC**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h1KN4xg5M2F",
        "outputId": "934b7423-8847-4829-a1a4-159bbdfaf268"
      },
      "source": [
        "# Add the data directory to DVC tracking\n",
        "!dvc add data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Add:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\n",
            "!\n",
            "Computing file/dir hashes (only done once)          |0.00 [00:00,      ?md5/s]\n",
            "Computing file/dir hashes (only done once)          |1.00 [00:01,   1.61s/md5]\n",
            "                                                                              \n",
            "!\n",
            "          |0.00 [00:00,       ?it/s]\n",
            "                                    \n",
            "Saving files:   0% 0/1 [00:00<?, ?file/s]\n",
            "Saving files:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\n",
            "                                                     \n",
            ".jBuVA6QSseug9qLLz4uRxk.tmp:   0% 0.00/60.2M [00:00<?, ?it/s]\n",
            ".jBuVA6QSseug9qLLz4uRxk.tmp:   0% 0.00/60.2M [00:00<?, ?it/s{'info': ''}]\n",
            ".jBuVA6QSseug9qLLz4uRxk.tmp:  61% 35.0M/57.4M [00:00<00:00, 364MB/s{'info': ''}]\n",
            "Add: 100% 1/1 [00:02<00:00,  2.39s/file{'info': ''}]\n",
            "\n",
            "To track the changes with git, run:\n",
            "\n",
            "\tgit add data.dvc .gitignore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtmT0NXT5Mzm",
        "outputId": "7a044765-80ab-47ff-cf04-36e4a66312ed"
      },
      "source": [
        "# Track the changes with Git\n",
        "!git add data.dvc .gitignore\n",
        "!git commit -m \"Add the data directory to DVC tracking\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 04c6454] Add the data directory to DVC tracking\n",
            " 2 files changed, 6 insertions(+)\n",
            " create mode 100644 data.dvc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhj6hOxE5phS"
      },
      "source": [
        "**Track Files with Git**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBkHS7AX5Mw6",
        "outputId": "881a428e-efda-4db8-af41-525c9f384193"
      },
      "source": [
        "!git add requirements.txt src/\n",
        "!git commit -m \"Add requirements and src to Git tracking\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 2ad0a53] Add requirements and src to Git tracking\n",
            " 4 files changed, 98 insertions(+)\n",
            " create mode 100644 requirements.txt\n",
            " create mode 100644 src/const.py\n",
            " create mode 100644 src/data_preprocessing.py\n",
            " create mode 100644 src/modeling.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nfGiK25RjNc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqwcpKyD6a4w"
      },
      "source": [
        "# Push the Files to the Remotes "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o39Xc_5HLKe8"
      },
      "source": [
        "**Push Git tracked files**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTPPNOi75Msn",
        "outputId": "d3efc383-3c37-4461-f29c-9a2f4e582de8"
      },
      "source": [
        "!git push https://{USER_NAME}:{TOKEN}@dagshub.com/{USER_NAME}/{REPO_NAME}.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 24, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:   4% (1/22)   \rCompressing objects:   9% (2/22)   \rCompressing objects:  13% (3/22)   \rCompressing objects:  18% (4/22)   \rCompressing objects:  22% (5/22)   \rCompressing objects:  27% (6/22)   \rCompressing objects:  31% (7/22)   \rCompressing objects:  36% (8/22)   \rCompressing objects:  40% (9/22)   \rCompressing objects:  45% (10/22)   \rCompressing objects:  50% (11/22)   \rCompressing objects:  54% (12/22)   \rCompressing objects:  59% (13/22)   \rCompressing objects:  63% (14/22)   \rCompressing objects:  68% (15/22)   \rCompressing objects:  72% (16/22)   \rCompressing objects:  77% (17/22)   \rCompressing objects:  81% (18/22)   \rCompressing objects:  86% (19/22)   \rCompressing objects:  90% (20/22)   \rCompressing objects:  95% (21/22)   \rCompressing objects: 100% (22/22)   \rCompressing objects: 100% (22/22), done.\n",
            "Writing objects:   4% (1/24)   \rWriting objects:   8% (2/24)   \rWriting objects:  12% (3/24)   \rWriting objects:  16% (4/24)   \rWriting objects:  20% (5/24)   \rWriting objects:  25% (6/24)   \rWriting objects:  29% (7/24)   \rWriting objects:  33% (8/24)   \rWriting objects:  41% (10/24)   \rWriting objects:  45% (11/24)   \rWriting objects:  50% (12/24)   \rWriting objects:  54% (13/24)   \rWriting objects:  58% (14/24)   \rWriting objects:  62% (15/24)   \rWriting objects:  66% (16/24)   \rWriting objects:  70% (17/24)   \rWriting objects:  75% (18/24)   \rWriting objects:  79% (19/24)   \rWriting objects:  83% (20/24)   \rWriting objects:  87% (21/24)   \rWriting objects:  91% (22/24)   \rWriting objects:  95% (23/24)   \rWriting objects: 100% (24/24)   \rWriting objects: 100% (24/24), 4.99 KiB | 2.49 MiB/s, done.\n",
            "Total 24 (delta 7), reused 0 (delta 0)\n",
            "To https://dagshub.com/prayas99/mark2.git\n",
            "   389bd1b..2ad0a53  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvIk4X4J9OrG"
      },
      "source": [
        "**Push DVC tracked files**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbum465z5MqI",
        "outputId": "94e10091-c844-4c12-adf3-7f238d396f9f"
      },
      "source": [
        "!dvc push -r origin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploading:   0% 0/2 [00:00<?, ?file/s{'info': ''}]\n",
            "data/enron.csv:   0% 0.00/60.2M [00:00<?, ?it/s]\n",
            "data/enron.csv:   0% 0.00/60.2M [00:00<?, ?it/s{'info': ''}]\n",
            "data/enron.csv:   1% 512k/57.4M [00:00<00:19, 3.13MB/s{'info': ''}]\n",
            "data/enron.csv:  17% 9.81M/57.4M [00:00<00:01, 46.1MB/s{'info': ''}]\n",
            "data/enron.csv:  31% 17.9M/57.4M [00:00<00:00, 53.1MB/s{'info': ''}]\n",
            "data/enron.csv:  41% 23.5M/57.4M [00:00<00:01, 33.5MB/s{'info': ''}]\n",
            "data/enron.csv:  48% 27.7M/57.4M [00:00<00:00, 33.8MB/s{'info': ''}]\n",
            "data/enron.csv:  55% 31.6M/57.4M [00:00<00:00, 34.9MB/s{'info': ''}]\n",
            "data/enron.csv:  62% 35.9M/57.4M [00:01<00:00, 37.4MB/s{'info': ''}]\n",
            "data/enron.csv:  71% 40.8M/57.4M [00:01<00:00, 41.0MB/s{'info': ''}]\n",
            "data/enron.csv:  79% 45.5M/57.4M [00:01<00:00, 38.1MB/s{'info': ''}]\n",
            "data/enron.csv:  87% 49.7M/57.4M [00:01<00:00, 39.5MB/s{'info': ''}]\n",
            "data/enron.csv:  93% 53.7M/57.4M [00:01<00:00, 32.0MB/s{'info': ''}]\n",
            "data/enron.csv: 100% 57.2M/57.4M [00:01<00:00, 29.0MB/s{'info': ''}]\n",
            "Uploading:  50% 1/2 [00:03<00:03,  3.38s/file{'info': ''}]\n",
            "data:   0% 0/69 [00:00<?, ?it/s]\n",
            "data:   0% 0/69 [00:00<?, ?it/s{'info': ''}]\n",
            "2 files pushed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clf4AiGQL-b5"
      },
      "source": [
        "# Process and Track Data Changes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pYOjB7HFvVe"
      },
      "source": [
        "We want to preprocess our data and track the results using DVC. by running the data_preprocessing.py module; we will generate four new files of processed data to the 'data' directory. We will track the new files with DVC and Git and push them to the remotes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgTU3txWFvG-",
        "outputId": "d0c6ddd6-f807-41c4-9d1b-fd13304e7c1d"
      },
      "source": [
        "# Process the Data\n",
        "!python src/data_preprocessing.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG] Preprocessing raw data \n",
            "     [DEBUG] Loading raw data\n",
            "     [DEBUG] Removing punctuation from Emails\n",
            "     [DEBUG] Label encoding target column\n",
            "     [DEBUG] vectorizing the emails by words\n",
            "     [DEBUG] Splitting data to train and test\n",
            "     [DEBUG] Saving data to file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDewJz-8ITTp",
        "outputId": "bd7c6004-8f06-4b65-d977-e89df21de2ef"
      },
      "source": [
        "# Track the Changes\n",
        "!dvc add data &> /dev/null \n",
        "!git add data.dvc\n",
        "!git commit -m \"Process raw-data and save it to data directory\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 9418994] Process raw-data and save it to data directory\n",
            " 1 file changed, 3 insertions(+), 3 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcojUi3gLzp6"
      },
      "source": [
        "**Push the Files to the remotes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyLE2IZNIhWD"
      },
      "source": [
        "!git push https://{USER_NAME}:{TOKEN}@dagshub.com/{USER_NAME}/{REPO_NAME}.git &> /dev/null \n",
        "\n",
        "!dvc push -r origin &> /dev/null "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idV9fU3cKgG8"
      },
      "source": [
        "# Create Data Science Experiments 🧪 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmoIGy8gLVn0"
      },
      "source": [
        "!pip3 install dagshub &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYaG1CILVBjn"
      },
      "source": [
        "**Run new experiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zAkSXJYLbuH",
        "outputId": "4eb277e8-e9ae-46b9-dc29-6d92368ad86b"
      },
      "source": [
        "!python3 src/modeling.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[DEBUG] Initialize Modeling \n",
            "     [DEBUG] Loading data sets for modeling\n",
            "     [DEBUG] Runing Random Forest Classifier\n",
            "     [INFO] Finished modeling with AUC Score: 0.931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyCw8PWqVGqZ"
      },
      "source": [
        "**Track the Experiment Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI0TRo6KLiR9",
        "outputId": "396f2d20-c00f-4842-cf02-80959bee9b96"
      },
      "source": [
        "!git add metrics.csv params.yml\n",
        "!git commit -m \"New Experiment - Random Forest Classifier with basic processing\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master e64f79e] New Experiment - Random Forest Classifier with basic processing\n",
            " 2 files changed, 23 insertions(+)\n",
            " create mode 100644 metrics.csv\n",
            " create mode 100644 params.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ_Sgu7fVV5m"
      },
      "source": [
        "**Push the Files to the Remotes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfeE3qnfVV5n",
        "outputId": "d05cb9a4-e81a-4354-f56c-bc74219bc0fb"
      },
      "source": [
        "!git push https://{USER_NAME}:{TOKEN}@dagshub.com/{USER_NAME}/{REPO_NAME}.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 4, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  25% (1/4)   \rCompressing objects:  50% (2/4)   \rCompressing objects:  75% (3/4)   \rCompressing objects: 100% (4/4)   \rCompressing objects: 100% (4/4), done.\n",
            "Writing objects:  25% (1/4)   \rWriting objects:  50% (2/4)   \rWriting objects:  75% (3/4)   \rWriting objects: 100% (4/4)   \rWriting objects: 100% (4/4), 647 bytes | 647.00 KiB/s, done.\n",
            "Total 4 (delta 1), reused 0 (delta 0)\n",
            "To https://dagshub.com/prayas99/mark2.git\n",
            "   9418994..e64f79e  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}